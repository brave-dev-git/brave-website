---
title: "När AI leder attacken: vem håller i ratten när vi kör fort?"
description: "En rapport från Anthropic beskriver ett skifte: AI gör 80–90 % av arbetet, människan blir dirigent. Det viktiga är inte panik – utan styrning och ansvar."
date: 2026-01-17
tags: ["AI", "governance", "riskhantering", "cybersäkerhet"]
draft: false
---

Jag får inte kalla kårar så ofta av en säkerhetsrapport längre.

Men Anthropics genomlysning av en **AI-orkestrerad** cyberoperation fick mig att stanna upp. Inte för att det bevisar att “AI tar över allt i morgon”, utan för att den fångar ett skifte som många av oss pratat om teoretiskt – och som nu börjar bli praktiskt.

Anthropic beskriver hur en avancerad aktör använde en kommersiell AI-plattform och dess mer agentiska förmågor i en spionageoperation. Rapporten placerar mycket av arbetet hos AI: uppdelning av uppgifter, iteration, sammanställning och genomförande – med människan mer som dirigent än operatör. :contentReference[oaicite:4]{index=4}

## Skiftet som betyder något

Det finns en version av den här diskussionen som fastnar i detaljer:
- “Hur många steg gjorde AI?”
- “Vad menas med 80–90 %?”
- “Var det verkligen autonomt?”

Det är intressant – men inte den viktigaste poängen.

Den viktiga poängen är att **arbetsdelningen förändras**:
- AI blir mer av en exekverande motor,
- människan flyttar upp en nivå och styr,
- och infrastrukturen som krävs för att skala finns redan i plattformarna.

Det är där jag tycker att det här blir en vattendelare: vi går från “angripare som använder AI som verktyg” till “AI-system som driver stora delar av angreppet”.

## “Plattformarna har safeguards” – ett argument vi har hört förut

När jag pratar om AI-risker hör jag ofta:
> “Men plattformarna har ju safeguards.”

Det påminner mig om ett annat argument som var vanligt i en annan bransch:
> “Sociala medier kommer att självreglera bort hat och desinformation.”

Vi vet hur det gick.

Poängen är inte att AI-leverantörer är “onda”. Poängen är att incitamenten i snabbväxande plattformsmarknader sällan gör säkerhet till första prioritet – om inte marknaden eller regleringen tvingar fram det.

Och här tycker jag att vi ofta saknar ett vuxet samtal om tre saker.

## Tre frågor vi behöver prata mer om

### 1) Incitamenten
Kan vi förlita oss på att kommersiella aktörer konsekvent väljer säkerhet före tillväxt – även när det kostar?

Anthropics rapport är i sig ett exempel på ett företag som lyfter risker offentligt. Men den påminner också om att missbruk sker även när försvar finns. :contentReference[oaicite:5]{index=5}

### 2) Ansvarsfördelningen
Vem bär ansvar när AI används i skadliga operationer?
- plattformen?
- den som bygger agentflöden?
- slutanvändaren?
- staten?

I dag hamnar för mycket på “någon annans bord”. Det är bekvämt – tills det inte är det.

### 3) Styrningen
Hur väver vi in AI-risker i befintlig governance, istället för att skapa ett nytt sidospår?

Jag tror att många organisationer kommer att göra fel här genom att skapa en AI-policy som lever i ett dokumentbibliotek, medan AI-användningen lever i verktyg, integrationer och workflow-automatisering.

## Bergsvägen utan räcke

För mig handlar det här inte om att bromsa AI.

Det handlar om att erkänna att vi kör fort på en bergsväg – och att någon måste bygga räckena innan första stora olyckan.

Det är också därför det är så viktigt att inte fastna i teknikdetaljer. Räckena handlar oftast om klassiska saker:
- åtkomst
- spårbarhet
- begränsning av befogenheter
- tydlig eskalering när något avviker

## Vad är “räcken” i praktiken?

Om jag skulle översätta det till fem praktiska frågor för en ledningsgrupp/IT-ledning:

1) **Vilken data får AI röra – och var hamnar den?**  
Det här är sällan en teknisk fråga, det är en risk- och ansvarfråga.

2) **Vilka actions får AI göra?**  
Skillnaden mellan “skriv ett utkast” och “gör ändringar i system” är enorm.

3) **Hur ser spårbarheten ut?**  
Kan vi i efterhand förstå vad som hände, vad som användes och vad som beslutades?

4) **Vem kan stänga av flöden?**  
Finns det en kill switch när något beter sig fel?

5) **Har vi övat en incident där AI är inblandad?**  
Det är i övningen man ser om styrningen faktiskt fungerar.

## En ny typ av risk – men samma behov av ledarskap

AI-risker är nya på vissa sätt. Men i ett annat perspektiv är de gamla:
teknik förändras snabbare än styrning, och vi måste hinna ikapp med ansvar.

Anthropics rapport är läsvärd som fallstudie, inte som domedag. :contentReference[oaicite:6]{index=6}

Den påminner oss om frågan som jag tycker är mest intressant:

**Vem håller i ratten – när vi bygger system som kör fortare än vi hinner tänka?**
